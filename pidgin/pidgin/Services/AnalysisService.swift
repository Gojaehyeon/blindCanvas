//
//  AnalysisService.swift
//  pidgin
//
//  Created by go on 11/1/25.
//

import Foundation
import AppKit

@MainActor
final class AnalysisService {
    static let shared = AnalysisService()
    
    private let captureService = ScreenCaptureService.shared
    private let gptClient = GPTClient.shared
    private let ttsService = TextToSpeechService.shared
    
    private init() {}
    
    /// ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: ìº¡ì²˜ â†’ GPT ë¶„ì„ â†’ TTS ì¬ìƒ
    /// - Parameters:
    ///   - rect: ìº¡ì²˜í•  í™”ë©´ ì˜ì—­
    ///   - mode: ë¶„ì„ ëª¨ë“œ (ì‹œì /êµ¬ì¡°ì )
    ///   - appState: ìƒíƒœ ì—…ë°ì´íŠ¸ìš© AppState
    func analyzeRegion(
        _ rect: CGRect,
        mode: AppState.AnalysisMode,
        appState: AppState
    ) async {
        // ì˜¤ë²„ë ˆì´ê°€ ë³´ì´ëŠ” ìƒíƒœì¸ì§€ í™•ì¸
        guard appState.overlayVisible else {
            print("âš ï¸ Overlay is not visible, skipping analysis")
            return
        }
        
        // TTS ì„¤ì • ì—…ë°ì´íŠ¸ (ë¶„ì„ ì‹œì‘ ì „ì— ë¯¸ë¦¬ ì„¤ì •)
        print("ğŸ”§ Updating TTS settings: rate=\(appState.ttsRate), gender=\(appState.ttsVoiceGender)")
        ttsService.updateSettings(rate: appState.ttsRate, voiceGender: appState.ttsVoiceGender)
        
        // 1. ìƒíƒœë¥¼ requestingë¡œ ë³€ê²½
        appState.selectionState = .requesting
        appState.analysisMode = mode
        appState.errorMessage = nil
        
        do {
            // 2. í™”ë©´ ìº¡ì²˜
            guard let image = try await captureService.captureRegion(rect) else {
                throw AnalysisError.captureFailed
            }
            
            // ì˜¤ë²„ë ˆì´ê°€ ì—¬ì „íˆ ë³´ì´ëŠ”ì§€ ë‹¤ì‹œ í™•ì¸ (ìº¡ì²˜ í›„)
            guard appState.overlayVisible else {
                print("âš ï¸ Overlay closed during capture, aborting analysis")
                appState.selectionState = .locked
                return
            }
            
            // 3. í”„ë¡¬í”„íŠ¸ ìƒì„±
            let prompt = PromptBuilder.prompt(for: mode)
            
            // 4. GPT ë¶„ì„ ìš”ì²­
            let response = try await gptClient.analyzeImage(image, withPrompt: prompt)
            
            // ì˜¤ë²„ë ˆì´ê°€ ì—¬ì „íˆ ë³´ì´ëŠ”ì§€ ë‹¤ì‹œ í™•ì¸ (GPT ì‘ë‹µ í›„)
            guard appState.overlayVisible else {
                print("âš ï¸ Overlay closed during GPT analysis, aborting TTS")
                appState.selectionState = .locked
                return
            }
            
            // 5. ì‘ë‹µ ì €ì¥
            appState.analysisResponse = response
            
            // 6. requesting ìƒíƒœë¥¼ ë¨¼ì € í•´ì œí•˜ê³  TTS ì¬ìƒ ì‹œì‘
            appState.selectionState = .locked
            appState.isTTSPlaying = true
            
            // TTS ì„¤ì • ì ìš©í•˜ì—¬ ì¬ìƒ
            ttsService.speak(text: response) {
                Task { @MainActor in
                    // ì˜¤ë²„ë ˆì´ê°€ ì—¬ì „íˆ ë³´ì´ëŠ”ì§€ í™•ì¸ í›„ ìƒíƒœ ì—…ë°ì´íŠ¸
                    appState.isTTSPlaying = false
                    if appState.overlayVisible {
                        appState.selectionState = .locked
                    }
                }
            }
            
        } catch {
            // ì—ëŸ¬ ì²˜ë¦¬
            appState.errorMessage = error.localizedDescription
            if appState.overlayVisible {
                appState.selectionState = .locked
            }
            appState.isTTSPlaying = false
            
            print("âŒ Analysis error: \(error)")
        }
    }
}

enum AnalysisError: Error, LocalizedError {
    case captureFailed
    
    var errorDescription: String? {
        switch self {
        case .captureFailed:
            return "í™”ë©´ ìº¡ì²˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        }
    }
}

