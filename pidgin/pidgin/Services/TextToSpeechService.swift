//
//  TextToSpeechService.swift
//  pidgin
//
//  Created by go on 11/1/25.
//

import AVFoundation
import Foundation
import AppKit

@MainActor
final class TextToSpeechService: NSObject {
    static let shared = TextToSpeechService()
    
    private let apiKey: String
    private let baseURL = URL(string: "https://api.openai.com/v1/audio/speech")!
    private var currentPlayer: AVPlayer?
    private var currentPlayerItem: AVPlayerItem?
    private var currentTempURL: URL?
    private var currentCompletion: (() -> Void)?
    private var onPlaybackStarted: (() -> Void)?
    
    // ì„¤ì • (AppStateì—ì„œ ì£¼ì…ë°›ìŒ)
    var rate: Float = 0.5  // 0.0 ~ 1.0, OpenAIëŠ” 0.25 ~ 4.0ì´ë¯€ë¡œ ë³€í™˜ í•„ìš”
    var voiceGender: AppState.VoiceGender = .female
    var provider: AppState.TTSProvider = .openAI
    var voiceIdentifier: String = ""  // ì„ íƒëœ ìŒì„± ID (Apple TTSìš©)
    
    // Apple TTSìš©
    private let synthesizer = AVSpeechSynthesizer()
    
    // OpenAI TTS ìŒì„± ì˜µì…˜
    enum OpenAIVoice: String {
        case alloy = "alloy"
        case echo = "echo"
        case fable = "fable"
        case onyx = "onyx"
        case nova = "nova"      // í•œêµ­ì–´ì— ì í•©
        case shimmer = "shimmer" // í•œêµ­ì–´ì— ì í•©
    }
    
    override init() {
        self.apiKey = Secrets.openAIKey
        super.init()
        synthesizer.delegate = self
        
        // AVPlayer ì¬ìƒ ì™„ë£Œ ì•Œë¦¼ ì„¤ì •
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(playerDidFinishPlaying),
            name: .AVPlayerItemDidPlayToEndTime,
            object: nil
        )
    }
    
    deinit {
        NotificationCenter.default.removeObserver(self)
        
        // deinitì—ì„œëŠ” @MainActor ë©”ì„œë“œë¥¼ í˜¸ì¶œí•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì§ì ‘ ì •ë¦¬
        currentPlayer?.pause()
        
        // Observer ì œê±°
        if let playerItem = currentPlayerItem {
            playerItem.removeObserver(self, forKeyPath: "status")
        }
        
        // ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if let tempURL = currentTempURL {
            try? FileManager.default.removeItem(at: tempURL)
        }
        
        currentPlayer = nil
        currentPlayerItem = nil
        currentTempURL = nil
        currentCompletion = nil
    }
    
    /// ì„¤ì • ì—…ë°ì´íŠ¸
    func updateSettings(rate: Float, voiceGender: AppState.VoiceGender, provider: AppState.TTSProvider, voiceIdentifier: String = "") {
        self.rate = rate
        self.voiceGender = voiceGender
        self.provider = provider
        self.voiceIdentifier = voiceIdentifier
    }
    
    /// OpenAI rateë¥¼ ë³€í™˜ (0.0~1.0 -> 0.5~1.5)
    private func convertRate(_ rate: Float) -> Float {
        // 0.0 -> 0.5 (ëŠë¦¼), 0.5 -> 1.0 (ë³´í†µ), 1.0 -> 1.5 (ë¹ ë¦„)
        // OpenAI speed ë²”ìœ„ëŠ” 0.25~4.0ì´ì§€ë§Œ, ë” ìì—°ìŠ¤ëŸ¬ìš´ ë²”ìœ„ë¡œ ì œí•œ
        return 0.5 + (rate * 1.0)
    }
    
    /// ì„±ë³„ì— ë§ëŠ” OpenAI ìŒì„± ì„ íƒ
    private func selectedVoice() -> OpenAIVoice {
        switch voiceGender {
        case .female:
            return .nova  // í•œêµ­ì–´ ì—¬ì„± ìŒì„±ì— ì í•©
        case .male:
            return .onyx  // í•œêµ­ì–´ ë‚¨ì„± ìŒì„±ì— ì í•©
        }
    }
    
    /// í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ì¬ìƒ
    /// - Parameters:
    ///   - text: ì¬ìƒí•  í…ìŠ¤íŠ¸
    ///   - onStarted: ì¬ìƒ ì‹œì‘ ì½œë°± (ì‹¤ì œë¡œ ì¬ìƒì´ ì‹œì‘ë  ë•Œ í˜¸ì¶œ)
    ///   - completion: ì¬ìƒ ì™„ë£Œ ì½œë°±
    func speak(
        text: String,
        onStarted: (() -> Void)? = nil,
        completion: (() -> Void)? = nil
    ) {
        // ê¸°ì¡´ ì¬ìƒ ì¤‘ì§€
        stop()
        
        currentCompletion = completion
        onPlaybackStarted = onStarted
        
        // ì œê³µìì— ë”°ë¼ ë‹¤ë¥¸ TTS ì‚¬ìš©
        switch provider {
        case .openAI:
            // OpenAI TTS API í˜¸ì¶œ (ë¹„ë™ê¸°ë¡œ ì‹¤í–‰í•˜ë˜ ì¦‰ì‹œ ì‹œì‘)
            Task { @MainActor in
                let startTime = Date()
                do {
                    print("ğŸ¤ GPT TTS ì‹œì‘: \(text.prefix(50))...")
                    let apiStartTime = Date()
                    let audioData = try await generateSpeech(text: text)
                    let apiTime = Date().timeIntervalSince(apiStartTime)
                    print("â±ï¸ API í˜¸ì¶œ ì™„ë£Œ: \(String(format: "%.2f", apiTime))ì´ˆ, ë°ì´í„° í¬ê¸°: \(audioData.count) bytes")
                    
                    let playStartTime = Date()
                    await playAudio(data: audioData)
                    let playTime = Date().timeIntervalSince(playStartTime)
                    print("â±ï¸ ì¬ìƒ ì‹œì‘ ì™„ë£Œ: \(String(format: "%.2f", playTime))ì´ˆ")
                    
                    let totalTime = Date().timeIntervalSince(startTime)
                    print("â±ï¸ ì´ ì†Œìš” ì‹œê°„: \(String(format: "%.2f", totalTime))ì´ˆ")
                } catch {
                    print("âŒ TTS ì˜¤ë¥˜: \(error.localizedDescription)")
                    // ì—ëŸ¬ ë°œìƒ ì‹œ completion í˜¸ì¶œ
                    currentCompletion?()
                    currentCompletion = nil
                    onPlaybackStarted = nil
                }
            }
        case .apple:
            // Apple TTS ì‚¬ìš© (ì¦‰ì‹œ ì¬ìƒ)
            speakWithAppleTTS(text: text)
        }
    }
    
    /// Apple TTSë¡œ ì¬ìƒ
    private func speakWithAppleTTS(text: String) {
        let utterance = AVSpeechUtterance(string: text)
        
        // ì„ íƒëœ ìŒì„± IDê°€ ìˆìœ¼ë©´ í•´ë‹¹ ìŒì„± ì‚¬ìš©
        let selectedVoice: AVSpeechSynthesisVoice?
        if !voiceIdentifier.isEmpty {
            selectedVoice = AVSpeechSynthesisVoice(identifier: voiceIdentifier)
        } else {
            // ê¸°ë³¸ê°’: Yuna
            let allVoices = AVSpeechSynthesisVoice.speechVoices()
            selectedVoice = allVoices.first { $0.name.localizedCaseInsensitiveContains("Yuna") }
        }
        
        utterance.voice = selectedVoice 
            ?? AVSpeechSynthesisVoice(language: "ko-KR")
            ?? AVSpeechSynthesisVoice(language: "en-US")
        utterance.rate = rate
        utterance.pitchMultiplier = 1.0
        utterance.volume = 1.0
        
        // ì¬ìƒ ì‹œì‘ ì•Œë¦¼
        onPlaybackStarted?()
        onPlaybackStarted = nil
        
        synthesizer.speak(utterance)
    }
    
    /// OpenAI TTS APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± ìƒì„±
    private func generateSpeech(text: String) async throws -> Data {
        let requestBody: [String: Any] = [
            "model": "tts-1",  // ë¹ ë¥¸ ëª¨ë¸ (tts-1-hdë³´ë‹¤ í›¨ì”¬ ë¹ ë¦„)
            "input": text,
            "voice": selectedVoice().rawValue,
            "speed": convertRate(rate)
        ]
        
        var request = URLRequest(url: baseURL)
        request.httpMethod = "POST"
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.timeoutInterval = 15.0  // íƒ€ì„ì•„ì›ƒ ì¤„ì„
        request.httpBody = try JSONSerialization.data(withJSONObject: requestBody)
        
        // ìµœì í™”ëœ URLSession ì‚¬ìš© (ìºì‹œ ë¹„í™œì„±í™”, ë¹ ë¥¸ ì—°ê²°)
        let config = URLSessionConfiguration.default
        config.timeoutIntervalForRequest = 15.0
        config.timeoutIntervalForResource = 15.0
        config.urlCache = nil
        config.requestCachePolicy = .reloadIgnoringLocalCacheData
        let session = URLSession(configuration: config)
        
        let (data, response) = try await session.data(for: request)
        
        guard let httpResponse = response as? HTTPURLResponse else {
            throw TTSError.invalidResponse
        }
        
        guard (200...299).contains(httpResponse.statusCode) else {
            if let errorData = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
               let error = errorData["error"] as? [String: Any],
               let message = error["message"] as? String {
                throw TTSError.apiError(message)
            }
            throw TTSError.httpError(httpResponse.statusCode)
        }
        
        return data
    }
    
    /// ì˜¤ë””ì˜¤ ë°ì´í„° ì¬ìƒ
    private func playAudio(data: Data) async {
        let playStartTime = Date()
        
        // ì„ì‹œ íŒŒì¼ì— ì €ì¥
        let tempURL = FileManager.default.temporaryDirectory
            .appendingPathComponent(UUID().uuidString)
            .appendingPathExtension("mp3")
        
        do {
            // íŒŒì¼ ì €ì¥
            let writeStartTime = Date()
            try data.write(to: tempURL)
            let writeTime = Date().timeIntervalSince(writeStartTime)
            print("â±ï¸ íŒŒì¼ ì €ì¥: \(String(format: "%.2f", writeTime))ì´ˆ")
            
            currentTempURL = tempURL
            
            // AVPlayerItem ìƒì„±
            let createStartTime = Date()
            let playerItem = AVPlayerItem(url: tempURL)
            let player = AVPlayer(playerItem: playerItem)
            
            currentPlayer = player
            currentPlayerItem = playerItem
            
            // Observer ì¶”ê°€
            playerItem.addObserver(self, forKeyPath: "status", options: [.new], context: nil)
            
            let createTime = Date().timeIntervalSince(createStartTime)
            print("â±ï¸ Player ìƒì„±: \(String(format: "%.2f", createTime))ì´ˆ")
            
            // ì¬ìƒ ì‹œì‘ ì•Œë¦¼ì„ ì¦‰ì‹œ í˜¸ì¶œ
            onPlaybackStarted?()
            onPlaybackStarted = nil
            
            // ì¬ìƒ ì‹œì‘ (ì¤€ë¹„ë¥¼ ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ì¦‰ì‹œ)
            player.play()
            
            let totalPlayTime = Date().timeIntervalSince(playStartTime)
            print("â±ï¸ ì¬ìƒ ì‹œì‘ê¹Œì§€: \(String(format: "%.2f", totalPlayTime))ì´ˆ")
            
        } catch {
            print("âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜: \(error.localizedDescription)")
            currentCompletion?()
            currentCompletion = nil
        }
    }
    
    
    /// AVPlayerItem ìƒíƒœ ê´€ì°°
    override func observeValue(forKeyPath keyPath: String?, of object: Any?, change: [NSKeyValueChangeKey : Any]?, context: UnsafeMutableRawPointer?) {
        if keyPath == "status" {
            if let playerItem = object as? AVPlayerItem {
                if playerItem.status == .readyToPlay {
                    // ì¬ìƒ ì¤€ë¹„ ì™„ë£Œ
                } else if playerItem.status == .failed {
                    // ì¬ìƒ ì‹¤íŒ¨
                    currentCompletion?()
                    currentCompletion = nil
                    currentPlayer = nil
                }
            }
        }
    }
    
    /// ì¬ìƒ ì™„ë£Œ ì•Œë¦¼
    @objc private func playerDidFinishPlaying() {
        // ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if let tempURL = currentTempURL {
            try? FileManager.default.removeItem(at: tempURL)
            currentTempURL = nil
        }
        
        // Observer ì œê±°
        if let playerItem = currentPlayerItem {
            playerItem.removeObserver(self, forKeyPath: "status")
            currentPlayerItem = nil
        }
        
        currentCompletion?()
        currentCompletion = nil
        currentPlayer = nil
    }
    
    /// ìŒì„± ì¬ìƒ ì¤‘ì§€
    func stop() {
        currentPlayer?.pause()
        
        // Observer ì œê±°
        if let playerItem = currentPlayerItem {
            playerItem.removeObserver(self, forKeyPath: "status")
            currentPlayerItem = nil
        }
        
        // ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if let tempURL = currentTempURL {
            try? FileManager.default.removeItem(at: tempURL)
            currentTempURL = nil
        }
        
        // Apple TTS ì¤‘ì§€
        if synthesizer.isSpeaking {
            synthesizer.stopSpeaking(at: .immediate)
        }
        
        currentCompletion = nil
        onPlaybackStarted = nil
        currentPlayer = nil
    }
    
    var isSpeaking: Bool {
        switch provider {
        case .openAI:
            return currentPlayer?.rate ?? 0 > 0
        case .apple:
            return synthesizer.isSpeaking
        }
    }
}

// MARK: - AVSpeechSynthesizerDelegate

extension TextToSpeechService: AVSpeechSynthesizerDelegate {
    nonisolated func speechSynthesizer(
        _ synthesizer: AVSpeechSynthesizer,
        didFinish utterance: AVSpeechUtterance
    ) {
        Task { @MainActor in
            currentCompletion?()
            currentCompletion = nil
        }
    }
    
    nonisolated func speechSynthesizer(
        _ synthesizer: AVSpeechSynthesizer,
        didCancel utterance: AVSpeechUtterance
    ) {
        Task { @MainActor in
            currentCompletion?()
            currentCompletion = nil
        }
    }
}

// MARK: - Errors

enum TTSError: Error, LocalizedError {
    case invalidResponse
    case httpError(Int)
    case apiError(String)
    case networkError(Error)
    
    var errorDescription: String? {
        switch self {
        case .invalidResponse:
            return "ì˜ëª»ëœ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤."
        case .httpError(let code):
            return "HTTP ì˜¤ë¥˜: \(code)"
        case .apiError(let message):
            return "API ì˜¤ë¥˜: \(message)"
        case .networkError(let error):
            return "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: \(error.localizedDescription)"
        }
    }
}

